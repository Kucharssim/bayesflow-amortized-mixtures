{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonkucharsky/projects/bayesflow/amortized-mixture/.venv/lib/python3.11/site-packages/bayesflow/trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# for accessing src, stan, etc.\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../..\")))\n",
    "\n",
    "import bayesflow as bf\n",
    "import numpy as np\n",
    "from src.AmortizedMixture import *\n",
    "from src.models.NormalHmm import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NormalHmm(n_cls = 2, n_obs=[100, 100], separation=3.0)\n",
    "model.prior_means = [0.0, 0.0, -1.5, 1.00]\n",
    "model.prior_sds = [1.14,  1.14, 1.0, 0.65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = bf.networks.SequenceNetwork(summary_dim=model.n_par*2)\n",
    "amortized_posterior=bf.amortizers.AmortizedPosterior(\n",
    "            inference_net=bf.networks.InvertibleNetwork(num_params=model.n_par, num_coupling_layers=10, coupling_design=\"spline\"), \n",
    "            summary_net=summary_net,\n",
    "            summary_loss_fun=\"MMD\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "trainer = bf.trainers.Trainer(amortizer=amortized_posterior, generative_model=model, checkpoint_path=\"checkpoints/posterior\", configurator=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|██████████| 1000/1000 [02:04<00:00,  8.01it/s, Epoch: 1, Iter: 1000,Loss: 4.896,W.Decay: 0.131,Avg.Loss: 7.399,Avg.W.Decay: 0.184,LR: 5.00E-04]\n",
      "Training epoch 2: 100%|██████████| 1000/1000 [01:43<00:00,  9.64it/s, Epoch: 2, Iter: 1000,Loss: 4.074,W.Decay: 0.120,Avg.Loss: 4.373,Avg.W.Decay: 0.125,LR: 4.98E-04]\n",
      "Training epoch 3: 100%|██████████| 1000/1000 [01:40<00:00,  9.95it/s, Epoch: 3, Iter: 1000,Loss: 3.315,W.Decay: 0.111,Avg.Loss: 3.897,Avg.W.Decay: 0.116,LR: 4.96E-04]\n",
      "Training epoch 4: 100%|██████████| 1000/1000 [01:40<00:00,  9.93it/s, Epoch: 4, Iter: 1000,Loss: 3.293,W.Decay: 0.102,Avg.Loss: 3.598,Avg.W.Decay: 0.106,LR: 4.92E-04]\n",
      "Training epoch 5: 100%|██████████| 1000/1000 [01:37<00:00, 10.31it/s, Epoch: 5, Iter: 1000,Loss: 3.593,W.Decay: 0.093,Avg.Loss: 3.213,Avg.W.Decay: 0.097,LR: 4.88E-04]\n",
      "Training epoch 6: 100%|██████████| 1000/1000 [01:34<00:00, 10.54it/s, Epoch: 6, Iter: 1000,Loss: 2.224,W.Decay: 0.085,Avg.Loss: 2.874,Avg.W.Decay: 0.089,LR: 4.82E-04]\n",
      "Training epoch 7: 100%|██████████| 1000/1000 [01:37<00:00, 10.30it/s, Epoch: 7, Iter: 1000,Loss: 2.499,W.Decay: 0.077,Avg.Loss: 2.657,Avg.W.Decay: 0.081,LR: 4.76E-04]\n",
      "Training epoch 8: 100%|██████████| 1000/1000 [01:40<00:00,  9.98it/s, Epoch: 8, Iter: 1000,Loss: 2.130,W.Decay: 0.069,Avg.Loss: 2.524,Avg.W.Decay: 0.073,LR: 4.69E-04]\n",
      "Training epoch 9: 100%|██████████| 1000/1000 [01:41<00:00,  9.87it/s, Epoch: 9, Iter: 1000,Loss: 2.393,W.Decay: 0.063,Avg.Loss: 2.393,Avg.W.Decay: 0.066,LR: 4.61E-04]\n",
      "Training epoch 10: 100%|██████████| 1000/1000 [01:42<00:00,  9.75it/s, Epoch: 10, Iter: 1000,Loss: 1.746,W.Decay: 0.058,Avg.Loss: 2.214,Avg.W.Decay: 0.061,LR: 4.52E-04]\n",
      "Training epoch 11: 100%|██████████| 1000/1000 [01:50<00:00,  9.04it/s, Epoch: 11, Iter: 1000,Loss: 1.845,W.Decay: 0.055,Avg.Loss: 1.802,Avg.W.Decay: 0.056,LR: 4.43E-04]\n",
      "Training epoch 12: 100%|██████████| 1000/1000 [01:51<00:00,  8.93it/s, Epoch: 12, Iter: 1000,Loss: 0.673,W.Decay: 0.051,Avg.Loss: 1.604,Avg.W.Decay: 0.053,LR: 4.32E-04]\n",
      "Training epoch 13: 100%|██████████| 1000/1000 [01:51<00:00,  8.94it/s, Epoch: 13, Iter: 1000,Loss: 1.529,W.Decay: 0.049,Avg.Loss: 1.490,Avg.W.Decay: 0.050,LR: 4.21E-04]\n",
      "Training epoch 14:  32%|███▏      | 318/1000 [00:35<01:16,  8.91it/s, Epoch: 14, Iter: 318,Loss: 1.066,W.Decay: 0.048,Avg.Loss: 1.433,Avg.W.Decay: 0.048,LR: 4.17E-04]"
     ]
    }
   ],
   "source": [
    "%time\n",
    "h = trainer.train_online(epochs=50, iterations_per_epoch=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f\u001b[38;5;241m=\u001b[39mbf\u001b[38;5;241m.\u001b[39mdiagnostics\u001b[38;5;241m.\u001b[39mplot_losses(\u001b[43mh\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "f=bf.diagnostics.plot_losses(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model(1000, context = {'n_obs': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, _ = trainer.amortizer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plot_latent_space_2d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = df['parameters']\n",
    "posterior_samples = trainer.amortizer.sample(df, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plot_sbc_ecdf(posterior_samples, prior_samples, difference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plot_sbc_ecdf(posterior_samples, prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plot_z_score_contraction(posterior_samples, prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bf.diagnostics.plot_recovery(posterior_samples, prior_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
