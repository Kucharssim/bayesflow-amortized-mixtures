{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonkucharsky/projects/bayesflow/amortized-mixture/.venv/lib/python3.11/site-packages/bayesflow/trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "INFO:root:Loaded loss history from checkpoints/amortizer_classification/history_50.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/amortizer_classification/ckpt-50\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# for accessing src, stan, etc.\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../..\")))\n",
    "\n",
    "from amortizer_classification import trainer\n",
    "from bayesflow.diagnostics import plot_losses\n",
    "from tensorflow.keras.optimizers.legacy import Adam # type: ignore\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_sets = 15_000\n",
    "offline_data = trainer.generative_model(n_data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generated 500 simulations for validation.\n",
      "Training epoch 1: 100%|██████████| 59/59 [02:26<00:00,  2.48s/it, Epoch: 1, Batch: 59,forward.loss: 0.304,backward.loss:: 0.303,Avg.forward.loss: 0.335,Avg.backward.loss:: 0.336,LR: 4.87E-03]\n",
      "INFO:root:Validation, Epoch: 1, forward.loss: 0.315, backward.loss:: 0.316\n",
      "Training epoch 2: 100%|██████████| 59/59 [02:17<00:00,  2.33s/it, Epoch: 2, Batch: 59,forward.loss: 0.324,backward.loss:: 0.324,Avg.forward.loss: 0.317,Avg.backward.loss:: 0.318,LR: 4.51E-03]\n",
      "INFO:root:Validation, Epoch: 2, forward.loss: 0.316, backward.loss:: 0.318\n",
      "Training epoch 3: 100%|██████████| 59/59 [02:20<00:00,  2.38s/it, Epoch: 3, Batch: 59,forward.loss: 0.317,backward.loss:: 0.321,Avg.forward.loss: 0.313,Avg.backward.loss:: 0.315,LR: 3.94E-03]\n",
      "INFO:root:Validation, Epoch: 3, forward.loss: 0.321, backward.loss:: 0.324\n",
      "Training epoch 4: 100%|██████████| 59/59 [02:31<00:00,  2.56s/it, Epoch: 4, Batch: 59,forward.loss: 0.299,backward.loss:: 0.303,Avg.forward.loss: 0.302,Avg.backward.loss:: 0.305,LR: 3.22E-03]\n",
      "INFO:root:Validation, Epoch: 4, forward.loss: 0.299, backward.loss:: 0.299\n",
      "Training epoch 5: 100%|██████████| 59/59 [02:25<00:00,  2.47s/it, Epoch: 5, Batch: 59,forward.loss: 0.286,backward.loss:: 0.288,Avg.forward.loss: 0.290,Avg.backward.loss:: 0.292,LR: 2.43E-03]\n",
      "INFO:root:Validation, Epoch: 5, forward.loss: 0.286, backward.loss:: 0.289\n",
      "Training epoch 6: 100%|██████████| 59/59 [02:30<00:00,  2.55s/it, Epoch: 6, Batch: 59,forward.loss: 0.270,backward.loss:: 0.278,Avg.forward.loss: 0.279,Avg.backward.loss:: 0.283,LR: 1.65E-03]\n",
      "INFO:root:Validation, Epoch: 6, forward.loss: 0.288, backward.loss:: 0.292\n",
      "Training epoch 7: 100%|██████████| 59/59 [02:34<00:00,  2.62s/it, Epoch: 7, Batch: 59,forward.loss: 0.271,backward.loss:: 0.273,Avg.forward.loss: 0.272,Avg.backward.loss:: 0.277,LR: 9.55E-04]\n",
      "INFO:root:Validation, Epoch: 7, forward.loss: 0.271, backward.loss:: 0.278\n",
      "Training epoch 8: 100%|██████████| 59/59 [02:26<00:00,  2.48s/it, Epoch: 8, Batch: 59,forward.loss: 0.272,backward.loss:: 0.281,Avg.forward.loss: 0.265,Avg.backward.loss:: 0.271,LR: 4.16E-04]\n",
      "INFO:root:Validation, Epoch: 8, forward.loss: 0.265, backward.loss:: 0.272\n",
      "Training epoch 9: 100%|██████████| 59/59 [02:27<00:00,  2.51s/it, Epoch: 9, Batch: 59,forward.loss: 0.263,backward.loss:: 0.274,Avg.forward.loss: 0.261,Avg.backward.loss:: 0.268,LR: 8.75E-05]\n",
      "INFO:root:Validation, Epoch: 9, forward.loss: 0.264, backward.loss:: 0.270\n",
      "Training epoch 10: 100%|██████████| 59/59 [02:32<00:00,  2.59s/it, Epoch: 10, Batch: 59,forward.loss: 0.253,backward.loss:: 0.260,Avg.forward.loss: 0.260,Avg.backward.loss:: 0.266,LR: 0.00E+00]\n",
      "INFO:root:Validation, Epoch: 10, forward.loss: 0.263, backward.loss:: 0.270\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "epochs = 10\n",
    "batch_size=256\n",
    "iterations_per_epoch = int(n_data_sets/batch_size)\n",
    "schedule = CosineDecay(0.005, epochs * iterations_per_epoch, name = \"lr_decay\")\n",
    "optimizer = Adam(schedule, global_clipnorm = 1.0)\n",
    "h=trainer.train_offline(simulations_dict=offline_data, epochs=epochs, batch_size=batch_size, validation_sims=500, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
